{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc71d1a",
   "metadata": {},
   "source": [
    "# Chinese Text Segmentation (Maximal Matching)\n",
    "\n",
    "The Chinese language does not use spaces between words, so the computer's task is to determine word boundaries using a dictionary.\n",
    "\n",
    "### 1. Environment Setup\n",
    "We will import the necessary libraries and set the filenames.\n",
    "In a script, filenames are passed via the command line (`sys.argv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33836de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "MAXWORDLEN = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1296984",
   "metadata": {},
   "source": [
    "### 2. Reading the Dictionary (Dictionary Loading)\n",
    "\n",
    "The first step of the algorithm is to load a list of known Chinese words.\n",
    "We will read the file `chinesetrad_wordlist.utf8` and store the words in a **`set`** data structure.\n",
    "This is critical for performance: checking for the existence of a word in a `set` happens instantly (O(1)), whereas in a regular list (`list`), it would take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af9b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_help():\n",
    "    progname = sys.argv[0]\n",
    "    progname = progname.split('/')[-1] # strip out extended path\n",
    "    help = __doc__.replace('<PROGNAME>', progname, 1)\n",
    "    print('-' * 60, help, '-' * 60, file=sys.stderr)\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce67af",
   "metadata": {},
   "source": [
    "### 3. Implementing the Segmentation Algorithm (Maximal Matching)\n",
    "\n",
    "This is the main part of the work. The `segment` function takes a sentence (a string without spaces) and returns a list of found words.\n",
    "\n",
    "**How the \"Greedy Algorithm\" (Maximal Matching) works:**\n",
    "1. We start from the beginning of the sentence (position 0).\n",
    "2. We take the longest possible chunk of text (length `MAXWORDLEN = 5`).\n",
    "3. We check: is this chunk in our dictionary?\n",
    "    * **Yes:** Great, it's a word! We add it to the result and move forward by its length.\n",
    "    * **No:** We decrease the length of the chunk by 1 and check again.\n",
    "4. If the chunk length reaches 1 character, we consider this character a word (even if it's not in the dictionary), add it, and move 1 step forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0a23db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------ Automatically created module for IPython interactive environment ------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    }
   ],
   "source": [
    "if '-h' in sys.argv or len(sys.argv) != 4:\n",
    "    print_help()\n",
    "\n",
    "word_list_file = sys.argv[1]\n",
    "input_file = sys.argv[2]\n",
    "output_file = sys.argv[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a6386",
   "metadata": {},
   "source": [
    "### 4. Running File Processing (Main Loop)\n",
    "\n",
    "Now let's put it all together.\n",
    "We open the input file `chinesetext.utf8` with unsegmented text and the output file `MYRESULTS.utf8` to write the result.\n",
    "\n",
    "The script will read the input file line by line, apply our `segment` function to each line, and write the result (words separated by spaces) to the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55635243",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = set()\n",
    "\n",
    "with open(word_list_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        word = line.strip()\n",
    "        word_list.add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80245a1d",
   "metadata": {},
   "source": [
    "### 5. Function Testing\n",
    "\n",
    "Before processing the entire file, let's check our `segment` function on a single concrete example.\n",
    "This helps ensure that the algorithm works correctly, splits the string, and returns a list of words.\n",
    "We will join the resulting list with spaces to make the output readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c861296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(sent, wordset):\n",
    "    sent = sent.strip()\n",
    "    words = []\n",
    "    position = 0\n",
    "    \n",
    "    while position < len(sent):\n",
    "        word_len = MAXWORDLEN \n",
    "        \n",
    "        while word_len > 0:\n",
    "            \n",
    "            # Extract candidate word\n",
    "            candidate = sent[position : position + word_len]\n",
    "            \n",
    "            # Check the length of the candidate to avoid index error or equals to 1\n",
    "            if candidate in wordset or word_len == 1:\n",
    "                words.append(candidate)\n",
    "                position += word_len # change the position\n",
    "                break # found a word, break the inner loop\n",
    "            \n",
    "            word_len -= 1 # decrease the length of the candidate\n",
    "            \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1837331d",
   "metadata": {},
   "source": [
    "### 6. Main File Processing Loop (Main Loop)\n",
    "\n",
    "This is the final stage. We open the input file `chinesetext.utf8` for reading and the file `MYRESULTS.utf8` for writing the results.\n",
    "\n",
    "The script iterates through each line of the input file:\n",
    "1. Applies the `segment` function to split the line into words.\n",
    "2. Joins the resulting list of words into a single string separated by spaces.\n",
    "3. Writes the result to the output file (don't forget to add a newline character `\\n` at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed8c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, \"r\", encoding=\"utf-8\") as f_in:\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for line in f_in:\n",
    "            # 1. Segmenting the line\n",
    "            segmented_list = segment(line, word_list)\n",
    "            \n",
    "            # 2. Joining the segmented list into a single string\n",
    "            result_line = \" \".join(segmented_list)\n",
    "            \n",
    "            # 3. Writing the result line to the output file\n",
    "            f_out.write(result_line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da479f80",
   "metadata": {},
   "source": [
    "### 1. Run Segmentation\n",
    "\n",
    "In this cell, we execute the main script `chinese_segmentation_STARTER_CODE.py`.\n",
    "It takes the following inputs:\n",
    "1.  **Word List** (`chinesetrad_wordlist.utf8`) — a list of known Chinese words (dictionary).\n",
    "2.  **Input Text** (`chinesetext.utf8`) — the raw text without spaces that needs to be segmented.\n",
    "\n",
    "The result of the algorithm (segmented text) is saved to the file **`MYRESULTS.utf8`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699bdd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation complete. Results saved to MYRESULTS.utf8\n"
     ]
    }
   ],
   "source": [
    "!python chinese_segmentation_STARTER_CODE.py chinesetrad_wordlist.utf8 chinesetext.utf8 MYRESULTS.utf8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480bee49",
   "metadata": {},
   "source": [
    "### 2. Evaluation\n",
    "\n",
    "Now we evaluate the accuracy of our algorithm.\n",
    "The script `eval_chinese_segmentation.py` compares our result (`MYRESULTS.utf8`) against the **Gold Standard** (`chinesetext_goldstandard.utf8`).\n",
    "\n",
    "The script outputs two metrics:\n",
    "* **Word-level accuracy:** The percentage of words identified correctly.\n",
    "* **Sentence-level accuracy:** The percentage of sentences where every single word was identified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a09e862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total correct words: 88573\n",
      "Total gold-std words: 91627\n",
      "Word-level accuracy: 96.67%\n",
      "Sentence-level accuracy: 85.38%\n"
     ]
    }
   ],
   "source": [
    "!python eval_chinese_segmentation.py chinesetext_goldstandard.utf8 MYRESULTS.utf8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
